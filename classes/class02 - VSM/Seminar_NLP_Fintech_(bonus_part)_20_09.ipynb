{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Анализ новостных сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('lenta.csv', usecols = ['title', 'text', 'class'])\n",
    "\n",
    "\n",
    "#WARNING! Если вы используете WINDOWS, то Mystem() может работать медленно!\n",
    "#Если не хотите долго ждать, оставьте лишь часть данных!\n",
    "\n",
    "#Раскомментить данную строчку для пользователей Windows\n",
    "#df = df.head(200)\n",
    "# Warning! При использовании части данных, результаты могут несколько отличаться.\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "df.text = df.text.str.lower()\n",
    "df.text = df.text.apply(words_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "mystopwords = stopwords.words('russian') + ['это', 'наш' , 'тыс', 'млн', 'млрд', 'также',  'т', 'д']\n",
    "\n",
    "print(mystopwords)\n",
    "def  remove_stopwords(text, mystopwords = mystopwords):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    "df.text = df.text.apply(remove_stopwords)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m = Mystem()\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "df.text = df.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Удаление стоп-лемм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mystoplemmas = ['который','прошлый','сей', 'свой', 'наш', 'мочь', 'год']\n",
    "def  remove_stoplemmas(text, mystoplemmas = mystoplemmas):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in mystoplemmas])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "df.text = df.text.apply(remove_stoplemmas)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "lemmata = []\n",
    "for index, row in df.iterrows():\n",
    "    lemmata += row['text'].split()\n",
    "fd = FreqDist(lemmata)\n",
    "for i in fd.most_common(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение ключевых словосочетаний\n",
    "\n",
    "\n",
    "Ключевые слова и словосочетания сложно определить формально. Поскольку определений ключевых слов и словосочетаний множество, существует масса методов их извлечения:\n",
    "* с учителем VS без учителя\n",
    "* частотные VS по-сложнее\n",
    "* из одного текста VS из коллекции текстов\n",
    "* слова (униграммы) VS биграммы VS $N$-граммы\n",
    "* термины VS именованные сущности VS коллокации\n",
    "* последовательные слова VS с использованием окна"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основные этапы извлечения ключевых слов и словосочетаний:\n",
    "1. Порождение кандидатов\n",
    "2. Оценка свойст кандидатов\n",
    "3. Выбор лучших кандидатов\n",
    "\n",
    "### Основные этапы извлечения ключевых слов и словосочетаний:\n",
    "* Морфологические шаблоны\n",
    "* Меры ассоциации биграмм: PMI, T-Score, LLR\n",
    "* Графовые методы: TextRank [Mihalcea, Tarau, 2004]\n",
    "* Мера контрасности: tf-idf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Морфологические шаблоны\n",
    "\n",
    "Можно использовать Томита-парсер. Вообще говоря, (далее цитата) Томита-парсер создан для извлечения структурированных данных из текста на естественном языке. Вычленение фактов происходит при помощи контекстно-свободных грамматик и словарей ключевых слов. Парсер позволяет писать свои грамматики и добавлять словари для нужного языка. \n",
    "\n",
    "Простейший шаблон ПРИЛ + СУЩ\n",
    "\n",
    "```\n",
    "S -> Adj<gnc-agr[1]> Noun<rt,gnc-agr[1]>; \n",
    "```\n",
    "\n",
    "\n",
    "![pipeline](../img/tomita1.png)\n",
    "\n",
    "![ссылка](https://tech.yandex.ru/tomita/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Переезжаем из DataFrame в списки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "tokens_by_topic = []\n",
    "for topic in df['class'].unique():\n",
    "    tokens = []\n",
    "    sample = df[df['class']==topic]\n",
    "    for i in range(len(sample)):\n",
    "        tokens += sample.text.iloc[i].split()\n",
    "    tokens_by_topic.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Выберем событие, из текстов про которое будем извлекать ключевые слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "event_id = 6\n",
    "df['class'].unique()[event_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование мер связности \n",
    "\n",
    "\n",
    "$w_1, w_2$ -- два слова\n",
    "\n",
    "$f(w_1), f(w_2)$ -- их частоты\n",
    "\n",
    "$f(w_1, w_2)$ -- совместная частота биграммы $w_1 w_2$\n",
    "\n",
    "$N$ -- число слов\n",
    "\n",
    "$PMI(w_1, w_2) = \\log \\frac{f(w_1, w_2)}{f(w_1)f(w_2)}$\n",
    "\n",
    "$T-score(w_1, w_2) = \\frac{f(w_1,w_2)-f(w_1)*f(w_2)}{f(w_1,w_2)/N}$\n",
    "\n",
    "Другие меры связности: $\\chi^2$, $\\texttt{log likelihood}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Извлекаем биграммы по разным мерам связности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "N_best = 100 # число извлекаемых биграм\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures() # класс для мер ассоциации биграм\n",
    "finder = BigramCollocationFinder.from_words(tokens_by_topic[event_id]) # класс для хранения и извлечения биграм\n",
    "finder.apply_freq_filter(1) # избавимся от биграм, которые встречаются реже трех раз\n",
    "raw_freq_ranking = [' '.join(i) for i in finder.nbest(bigram_measures.raw_freq, N_best)] # выбираем топ-10 биграм по частоте \n",
    "tscore_ranking = [' '.join(i) for i in finder.nbest(bigram_measures.student_t, N_best)] # выбираем топ-100 биграм по каждой мере \n",
    "pmi_ranking =  [' '.join(i) for i in finder.nbest(bigram_measures.pmi, N_best)]\n",
    "llr_ranking = [' '. join(i) for i in finder.nbest(bigram_measures.likelihood_ratio, N_best)]\n",
    "chi2_ranking =  [' '.join(i) for i in finder.nbest(bigram_measures.chi_sq, N_best)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rankings = pd.DataFrame({ 'chi2': chi2_ranking, 'llr':llr_ranking, 't-score' : tscore_ranking, 'pmi': pmi_ranking, 'raw_freq':raw_freq_ranking})\n",
    "rankings = rankings[['raw_freq', 'pmi', 't-score', 'chi2', 'llr']]\n",
    "rankings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Похожи ли списки биграм?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "corr = spearmanr(rankings).correlation\n",
    "sns.heatmap(corr, annot=True, xticklabels = list(rankings), yticklabels = list(rankings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank\n",
    "\n",
    "* Вершины графа: слова\n",
    "* Ребра графа могут определяться по следующим правилам:\n",
    "    * Последовательные слова\n",
    "    * Слова внутри левого или правого окна в $\\pm$ 2-5 слов  \n",
    "\n",
    "* Ребра могут быть взвешенные или невзвешенные, направленные или ненаправленные\n",
    "* Любая мера центральности графа используется для определения важности вершин в графе. Слова, соответствующие наиболее важным вершинам, считаются ключевыми. \n",
    "* Если две соседние вершины оказываются важными, соответствующие им слова формируют ключевое словосочетание.\n",
    "\n",
    "PageRank: $PR(V_i)=(1-d)+d \\times \\sum_{V_j \\in In(V_i)} \\frac{PR(V_j)}{|Out(V_j)|}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Используем TextRank для извлечения ключевых слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.summarization import keywords\n",
    "text = ' '.join(tokens_by_topic[event_id])\n",
    "kw = keywords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rankings = pd.DataFrame({'Text Rank': kw.split('\\n')})\n",
    "rankings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Мера контрастности $tf-idf$\n",
    "\n",
    "\n",
    "\n",
    "Частота терма [Luhn, 1957]:  Важность терма в тексте пропорциональная его частоте.\n",
    "\n",
    "Обратная документная частота [Spaerck Jones, 1972]: Специфичность терма в тексте обратно пропорциональна числу текстов, в которых терм встречается. \n",
    "\n",
    "$tfidf(term, text, collection) = tf(term, document) \\times idf(term, collection)$\n",
    "\n",
    "Самая популярная комбинация весов: $f_{t,d} \\times \\log \\frac{|D|}{n_t+1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Извлекаем ключевые слова по $tf-idf$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 0)\n",
    "tfidf_matrix =  tfidf.fit_transform([' '.join(tokens) for tokens in tokens_by_topic])\n",
    "feature_names = tfidf.get_feature_names() \n",
    "tfidf_ranking = []\n",
    "dense = tfidf_matrix.todense()\n",
    "\n",
    "text = dense[1].tolist()[0]\n",
    "phrase_scores = [pair for pair in zip(range(0, len(text)), text) if pair[1] > 0]\n",
    "sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "phrases = []\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_phrase_scores][:40]:\n",
    "    tfidf_ranking.append(phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rankings = pd.DataFrame({'tf-idf': tfidf_ranking})\n",
    "rankings.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
