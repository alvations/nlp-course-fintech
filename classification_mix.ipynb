{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов\n",
    "\n",
    "## Постановка задачи\n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $c \\in C$ – классы \n",
    "\n",
    "* Бинарная классификация: $C = \\{0, 1\\}$ \n",
    "* Многоклассовая классификация [multiclass classification]: $C = \\{0, ..., K\\}$\n",
    "* Многотемная классификация [multi-label classification]: $C = \\{0,1\\}^K$\n",
    "\n",
    "## Примеры\n",
    "\n",
    "* Фильтрация спама: $C = \\{spam, ham\\}$ – бинарная классификация\n",
    "* Классификация по тональности: $C =  \\{neutral, positive, negative\\}$ – классификация с тремя классами\n",
    "* Рубрикация: $C \\in \\{религия, праздники, спорт, фестивали, ... \\}$ – классификация на несколько тем\n",
    "* Определение авторства:\n",
    "    * Этим ли автором написан текст: $ C = \\{0, 1\\}$?\n",
    "    * Кем из этих авторов написан текст: $ C = \\{a_1, a_2, a_3, ... \\}$?\n",
    "    * Пол автора: $ C = \\{f, m\\}$\n",
    "    \n",
    "### По правилам\n",
    "\n",
    "* Если в предложении встречается личное местоимение первого лица и глагол с окончанием женского рода, то пол автора = $f$.\n",
    "* Если доля положительно окрашенных прилагательтельных в отзыве больше доли отрицательно окрашенных прилагательных, то отзыв относится к классу $posititive$.\n",
    "\n",
    "### С использованием алгоритмов машинного обучения \n",
    "\n",
    "$ \\gamma : D \\rightarrow C$ – алгоритм классификации\n",
    "\n",
    "$({D^{train}, C^{train}})$ – обучающее множество \n",
    "\n",
    "$({D^{test}, C^{test}})$ – тестовое множество \n",
    "\n",
    "## Меры качества бинарной классификации \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th colspan=\"2\">gold <br>standart</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>positive</td>\n",
    "    <td>negative</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"2\">classification <br>output</td>\n",
    "    <td>positive</td>\n",
    "    <td>$tp$</td>\n",
    "    <td>$fp$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>negative</td>\n",
    "    <td>$fn$</td>\n",
    "    <td>$tn$</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "$precision = Pr =  \\frac{tp}{tp+fp} $ – точность \n",
    "\n",
    "$recall = R = \\frac{tp}{tp+fn} $ – полнота \n",
    "\n",
    "$F_2 = \\frac{2 Pr * R}{Pr + R}$ – $F$-мера \n",
    "\n",
    "$accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$ –  аккуратность  \n",
    "\n",
    "## Меры качества многоклассовой классификации \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th></th>\n",
    "    <th colspan=\"3\">gold <br>standart</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>$class_1$</td>\n",
    "    <td>$class_2$</td>\n",
    "    <td>$class_3$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"3\">classification <br>output</td>\n",
    "    <td>$class_1$</td>\n",
    "    <td>$tp_1$</td>\n",
    "    <td>$fp_{12}$</td>\n",
    "    <td>$fp_{13}$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$class_2$</td>\n",
    "    <td>$fn_{21}$</td>\n",
    "    <td>$tp_2$</td>\n",
    "    <td>$fp_{23}$</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$class_3$</td>\n",
    "    <td>$fn_{31}$</td>\n",
    "    <td>$fn_{32}$</td>\n",
    "    <td>$tp_3$</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Микро-усреднение:\n",
    "\n",
    "$micro-precision = micro-Pr =  \\frac{\\sum tp_i}{\\sum tp_i + \\sum fp_i} $ \n",
    "\n",
    "$micro-recall = micro-R = \\frac{\\sum tp_i}{\\sum tp_i+ \\sum fn_i } $\n",
    "\n",
    "Макро-усреднение:\n",
    "\n",
    "$macro-precision = macro-Pr =  \\frac{\\sum Pr_i}{|C|} $\n",
    "\n",
    "$macro-recall = macro-R = \\frac{\\sum R_i}{|C|} $ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные: это отзывы о ресторанах и оценка. Будем решать многоклассовую классификацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\tSentiment\tText\r\n",
      "0\t1\tIncredibly disappointing service. I mean really, really bad.\\n\\nWe placed an order for delivery at 6:30 pm on a Tuesday night, not the busiest night of the week, I'm sure. We were given an estimate of 30-40 minutes. After an hour my husband called to make sure our order wasn't forgotten. The young girl on the phone said that they were very busy and the driver was on his way to our house (less than a mile from the restaurant) at that time and should arrive in 10 minutes. After another 30 minutes we called back and asked to please cancel the order, after 1 1/2 hours we no longer wanted the food. The girl on the phone shouted at my husband that none of this was her fault and was reluctant to cancel our order. She wanted to charge us for food we never received!\\n\\nThe food is just not good enough for such poor service. If 18 year old college students can't answers phones and take simple orders don't hire them. It's simple.\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 2 train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  102583 train.data\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l train.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем выборку, поделим на трейн и тест так, чтобы в x_train был raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "train_file = csv.reader(open('train.data'), delimiter='\\t') \n",
    "next(train_file) \n",
    "train_set = [x for x in train_file]\n",
    "\n",
    "train_data, train_label = [line[2] for line in train_set], [line[1] for line in train_set]\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(train_data, train_label, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like this location because they have a drive-thru. Even though there is almost always a long line, they get you on your way fast. The staff is friendly and competent. Also, they rarely run out of anything (other locations seem to go through their entire inventory of breakfast sandwiches and scones by 9am).\\\\n\\\\nIf you are the type that does not drink your morning coffee inside a moving vehicle, they also have comfy chairs inside and decent patio seating.  The patio faces the parking lot and drive-thru but it does have shade umbrellas so it can be very pleasant in the morning.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим что будет, если применить самое простое решение: найти 100 самых частотных слов и использовать их в качестве признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "\n",
    "def create_bow_with_freq(data): \n",
    "    result = Counter() \n",
    "    for s in data:\n",
    "        result.update(s.strip().split()) \n",
    "    return list(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique \"words\":  484082\n"
     ]
    }
   ],
   "source": [
    "train_bow = create_bow_with_freq(x_train)\n",
    "print('Number of unique \"words\": ', len(train_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 654951),\n",
       " ('and', 492240),\n",
       " ('a', 411657),\n",
       " ('I', 385802),\n",
       " ('to', 359227),\n",
       " ('of', 248340),\n",
       " ('was', 240102),\n",
       " ('is', 184703),\n",
       " ('for', 167194),\n",
       " ('in', 162966)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_word = sorted(train_bow, key=lambda x: x[1], reverse=True)[:100]\n",
    "most_frequent_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bow_sample(bow, sample): \n",
    "    for s in sample: \n",
    "        s = s.strip().split() \n",
    "        yield { word: (word in s) for (word, _) in bow}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_train = [(x, y) for (x, y) in zip(make_bow_sample(most_frequent_word, x_train), y_train)]\n",
    "bow_validate = [b for b in make_bow_sample(most_frequent_word, x_validate)] # без категории, только словарь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся наивным байесовским классификатором. \n",
    "Плюс данного классификатора - можно посмотреть какиме слова оказались наиболее полезными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод наивного Байеса  [Multinomial naive Bayes classifier]\n",
    "\n",
    "Требуется оценить вероятность принадлежности документа $d \\in D$ классу $c \\in C$: $p(c|d)$. Каждый документ –  мешок слов, всего слов $|V|$.\n",
    "\t\n",
    "$p(c)$ – априорная вероятность класса $c$\n",
    "   \n",
    "$p(c|d)$ – апостериорная вероятность класса $c$\n",
    "\t\n",
    "$ p(c|d) = \\frac{p(d|c)p(c)}{p(d)} $\n",
    "\n",
    "Пусть документ $d$ описан признаками $f_1, \\dots, f_N$.\n",
    "\n",
    "$ c_{NB} = \\arg \\max _{c \\in C} p (c|d) = \\arg \\max_{c \\in C}  \\frac{p(d|c)p(c)}{p(d)} \\propto $\n",
    "\t\n",
    "$ \\propto \\arg \\max_{c \\in C} p(d|c)p(c)  = \\arg \\max_{c \\in C} p(f_1, f_2, \\dots, f_{N} | c)p(c)$\n",
    "\n",
    "### Предположение о независимости \n",
    "\n",
    "* Мешок слов: порядок слов не имеет значения\n",
    "* Условная независимость (наивное предположение): вероятности признаков $p(f_i|c_j)$ внутри класса $c_j$ независимы\n",
    "\n",
    "$p(f_1, f_2, \\dots, f_{N} | c) \\times  p(c) =   p(f_1|c) \\times p(f_2|c) \\times \\dots \\times p(f_{N}|c)  \\times p(c)$\n",
    "\n",
    "\n",
    "$C_{NB}=\\arg \\max_{c \\in C} p(c) \\times \\prod_{1 \\le i \\le N} p(f_i|c) $\n",
    "\n",
    "Допустим, что признаки $f_i$ – слова $w_i$, а $\\texttt{positions}$ – все позиции слов в документе.\n",
    "\n",
    "\n",
    "$C_{NB} = p(c) \\times \\prod_{i \\in \\texttt{positions}} p(w_i|c) $\n",
    "\n",
    "### Обучение наивного Байесовского классификатора\n",
    "\n",
    "#### ММП оценки вероятностей:\n",
    "\t\n",
    "$ \\widehat{p_(c_j)} = \\frac{| \\{d| d \\in c_j\\} |}{|D|} $\n",
    "\t\n",
    "$ \\widehat{p(w_i | c_j)} = \\frac{\\texttt{count}(w_i, c_j)}{\\sum_{w \\in V} \\texttt{count}(w, c_j)} $\n",
    "\t\n",
    "Создаем $|C|$ мегадокументов: каждый документ = все документы в одном классе, склеенные в один мегадокумент и вычисляем частоты $w$ в мегадокументах.\n",
    "\t\n",
    "#### Проблема нулевых вероятностей:  \n",
    "\n",
    "$\\texttt{count}(w_i, c_j)$ может быть равно нулю. \n",
    "\n",
    "Допустим, что каждое слово встречается как минимум $\\alpha$ раз в мешке слов.\n",
    "\t\n",
    "Преобразование Лапласа: $ \\frac{+\\alpha}{+\\alpha |V|}$\n",
    "\t\n",
    "$ \\widehat{p(w_i | c_j)} = \\frac{\\texttt{count}(w_i, c_j) + \\alpha}{(\\sum_{w \\in V} \\texttt{count}(w, c_j)) + \\alpha |V| } $\n",
    "\n",
    "### Пример. Тематическая классификация\n",
    "\t\n",
    "    \n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>документ</th>\n",
    "    <th>класс</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td rowspan=\"4\">обучающее<br>множество</td>\n",
    "    <td>Chinese Beijing Chinese</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Chinese Chinese Shanghai</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Chinese Macao</td>\n",
    "    <td>c</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tokyo Japan Chinese</td>\n",
    "    <td>j</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>тестовое<br>множество</td>\n",
    "    <td>Chinese Chinese Chinese Tokyo Japan</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Какой класс получим? Посчитайте.\n",
    "\n",
    "### Простой пример применения Наивного Байеса \n",
    "см в classification_names.html\n",
    "\n",
    "### Продолжаем на наших данных:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    love = True                5 : 1      =      3.5 : 1.0\n",
      "                   great = True                5 : 1      =      3.1 : 1.0\n",
      "                     was = False               5 : 1      =      2.7 : 1.0\n",
      "                  always = True                5 : 1      =      2.6 : 1.0\n",
      "                  pretty = True                3 : 1      =      2.5 : 1.0\n",
      "                      no = True                1 : 5      =      2.4 : 1.0\n",
      "                      he = True                1 : 4      =      2.4 : 1.0\n",
      "                      to = False               4 : 1      =      2.3 : 1.0\n",
      "                  didn't = True                2 : 5      =      2.3 : 1.0\n",
      "                    nice = True                4 : 1      =      2.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb = nltk.NaiveBayesClassifier.train(bow_train)\n",
    "print(nb.show_most_informative_features())\n",
    "predicted = [nb.classify(o) for o in bow_validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.378760544151\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy', np.mean(np.array([float(x) for x in predicted])== np.array([float(x) for x in y_validate])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры других классификаторов\n",
    "см classification_texts.html\n",
    "\n",
    "### На наших данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train1 = [float(v) for v in y_train]\n",
    "y_validate1 = [float(v) for v in y_validate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз будем действовать умнее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(encoding=u'utf-8', ngram_range=(1, 2), analyzer='word')\n",
    "Xtrain = tfidf.fit_transform(x_train)\n",
    "Xtest = tfidf.transform(x_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1, random_state=3,n_jobs=-1)\n",
    "lr.fit(Xtrain, y_train1)\n",
    "lr_pr = lr.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.590472475499\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy', np.mean(np.array([float(x) for x in lr_pr])== np.array([float(x) for x in y_validate])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда обучаем многоклассовую классификацию для такой задачи, не учитываем то, что метки 1 и 2 более похожи между собой, чем 4 и 5. Как это можно было бы учесть при обучении модели?\n",
    "\n",
    "# Задание на сейчас\n",
    "В материалах Кати Черняк https://github.com/echernyak/ML-for-compling/blob/master/l3_classification.ipynb найти другие классификаторы, применить к нашим данным, посчитать микро- и макро- усреднения.\n",
    "\n",
    "Подсказка: вам может пригодиться следующее преобразование (как минимум для predicted): np.array([float(y) for y in arr])\n",
    "\n",
    "Если результаты будут низкими, попробуйте объединить (1 и 2) и/или (4 и 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой алгоритм сработал лучше вcего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
